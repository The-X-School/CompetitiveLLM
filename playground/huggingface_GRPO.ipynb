{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f156ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# train_grpo.py\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "import multiprocessing\n",
    "import psutil\n",
    "import time\n",
    "import builtins\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "\n",
    "if (os.path.exists('./taco_train')):\n",
    "    TACO_train = load_from_disk('./taco_train')\n",
    "else:\n",
    "    TACO_train = load_dataset(\"BAAI/TACO\", split=\"train\")\n",
    "    TACO_train.save_to_disk('./taco_train')\n",
    "\n",
    "if (os.path.exists('./taco_valid')):\n",
    "    TACO_valid = load_from_disk('./taco_valid')\n",
    "else:\n",
    "    TACO_valid = load_dataset(\"BAAI/TACO\", split=\"test\")\n",
    "    TACO_valid.save_to_disk('./taco_valid')\n",
    "\n",
    "TACO_train = TACO_train \\\n",
    "    .rename_column('question', 'prompt') \\\n",
    "    .rename_column('solutions', 'completion')\n",
    "\n",
    "TACO_valid = TACO_valid \\\n",
    "    .rename_column('question', 'prompt') \\\n",
    "    .rename_column('solutions', 'completion')\n",
    "#prompt_to_completion_valid = {TACO_valid['prompt'][i]: TACO_valid['completion'][i] for i in range(len(TACO_valid))}\n",
    "    \n",
    "prompt_to_completion_train = {TACO_train[i]['prompt']: TACO_train[i]['input_output'] for i in range(len(TACO_train))}\n",
    "\n",
    "prompt_to_time = {TACO_train[i]['prompt']: TACO_train[i]['time_limit'] for i in range(len(TACO_train))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb43494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the code that will be used to test the code\n",
    "def test_code(code, cases, ex_out, time_limit):\n",
    "    score = 0\n",
    "    correct_cases = 0\n",
    "\n",
    "    def run_code(code, case_input, output_queue):\n",
    "        # Mock input\n",
    "        builtins.input = lambda: case_input\n",
    "\n",
    "        # Capture output\n",
    "        buf = io.StringIO()\n",
    "        sys.stdout = buf\n",
    "        try:\n",
    "            exec(code)\n",
    "        except Exception as e:\n",
    "            output_queue.put((\"ERROR\\n\", 0))\n",
    "            return\n",
    "        finally:\n",
    "            sys.stdout = sys.__stdout__\n",
    "\n",
    "        output_queue.put((buf.getvalue(), 0))  # memory will be added later\n",
    "\n",
    "    for i in range(len(cases)):\n",
    "        output_queue = multiprocessing.Queue()\n",
    "        p = multiprocessing.Process(target=run_code, args=(code, cases[i], output_queue))\n",
    "        p.start()\n",
    "        proc = psutil.Process(p.pid)\n",
    "\n",
    "        max_mem = 0\n",
    "        start_time = time.time()\n",
    "        first_mem = proc.memory_info().rss / 1024\n",
    "        while p.is_alive() and time.time() - start_time < time_limit:\n",
    "            try:\n",
    "                mem = proc.memory_info().rss / 1024  # in KB\n",
    "                max_mem = max(max_mem, mem)\n",
    "            except psutil.NoSuchProcess:\n",
    "                break\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        if p.is_alive():\n",
    "            p.terminate()\n",
    "            out = \"TIME LIMIT EXCEEDED\\n\"\n",
    "            score -= 1 / len(cases) * 10\n",
    "        else:\n",
    "            try:\n",
    "                out, _ = output_queue.get(timeout=1)\n",
    "            except:\n",
    "                out = \"ERROR\\n\"\n",
    "                score -= 1 / len(cases) * 50\n",
    "\n",
    "        #print(f\"Case {i+1}: Memory used â‰ˆ {int(max_mem)} KB\")\n",
    "\n",
    "        if out == ex_out[i]:\n",
    "            correct_cases += 1\n",
    "    score += correct_cases / len(cases) * 100\n",
    "    if correct_cases == len(cases):\n",
    "        score += 25\n",
    "    return score\n",
    "\n",
    "def extract_tags(completion, tag_start, tag_end):\n",
    "    return re.compile(f\"{tag_start}(.*?){tag_end}\").find(completion)\n",
    "\n",
    "def reward_check(completions, **kwargs):\n",
    "    #completions is the code???\n",
    "    rewards=[]\n",
    "    for completion in completions:\n",
    "        code = extract_tags(completion, \"<solution>\", \"</solution>\")\n",
    "        time_limit = prompt_to_time[kwargs['prompt']]\n",
    "        cases = prompt_to_completion_train[kwargs['prompt']]['inputs']\n",
    "        ex_out = prompt_to_completion_train[kwargs['prompt']]['outputs']\n",
    "        reward = test_code(code, cases, ex_out, time_limit)\n",
    "        rewards.append(reward)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_start = \"<think>\" \n",
    "reasoning_end   = \"</think>\"\n",
    "solution_start  = \"<solution>\"\n",
    "solution_end    = \"</solution>\"\n",
    "\n",
    "system_prompt = \\\n",
    "f\"\"\"You are given a problem.\n",
    "Think about the problem and provide your working out.\n",
    "Place it between {reasoning_start} and {reasoning_end}.\n",
    "Then, provide your solution between {solution_start}{solution_end}\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)\n",
    "training_args = GRPOConfig(output_dir=\"Qwen2-0.5B-GRPO\", logging_steps=10, per_device_train_batch_size=24)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "chat_template = \\\n",
    "    \"{% if messages[0]['role'] == 'system' %}\"\\\n",
    "        \"{{ messages[0]['content'] + eos_token }}\"\\\n",
    "        \"{% set loop_messages = messages[1:] %}\"\\\n",
    "    \"{% else %}\"\\\n",
    "        \"{{ '{system_prompt}' + eos_token }}\"\\\n",
    "        \"{% set loop_messages = messages %}\"\\\n",
    "    \"{% endif %}\"\\\n",
    "    \"{% for message in loop_messages %}\"\\\n",
    "        \"{% if message['role'] == 'user' %}\"\\\n",
    "            \"{{ message['content'] }}\"\\\n",
    "        \"{% elif message['role'] == 'assistant' %}\"\\\n",
    "            \"{{ message['content'] + eos_token }}\"\\\n",
    "        \"{% endif %}\"\\\n",
    "    \"{% endfor %}\"\\\n",
    "    \"{% if add_generation_prompt %}{{ '{reasoning_start}' }}\"\\\n",
    "    \"{% endif %}\"\n",
    "\n",
    "# Replace with out specific template:\n",
    "chat_template = chat_template\\\n",
    "    .replace(\"'{system_prompt}'\",   f\"'{system_prompt}'\")\\\n",
    "    .replace(\"'{reasoning_start}'\", f\"'{reasoning_start}'\")\n",
    "tokenizer.chat_template = chat_template\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    reward_funcs=reward_check,\n",
    "    args=training_args,\n",
    "    train_dataset=[TACO_train[0]],\n",
    "    eval_dataset=[TACO_valid[0]]\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
